# Release 0

## Table of Contents

* [Introduction](#introduction)
  * [About me](#about-me)
  * [About Credera](#about-credera)
* [Knowledge, Skills and Behaviours](#knowledge-skills-and-behaviours)
* [Table of Tickets](#table-of-tickets)
* [Ticket 1](#ticket-1)
  * [Project Background](#project-background)
  * [Ticket Background](#ticket-background)
  * [Learning and Research](#learning-and-research)
  * [Completing the Ticket](#completing-the-ticket)
  * [Problems and Solutions](#problems-and-solutions)
  * [Conclusion](#conclusion)

## Introduction

### About Me

My Name is Hotu, and I'm from New Zealand. Before landing a position as an apprentice with Credera I was a chef for about 7 years. When I was still in highschool and the dream of becoming a snowboard instructor, when I finished highschool I moved to a ski town in the hopes of becoming one.
Better planing would have told me that I had made the trip too late in the season. Desperate for a job I applied everywhere.My hopes and dreams were dashed, and not wanting to pack up and leave I applied to everywhere I could, luckily a couple guys owned a seasonal pop-up pizza joint in the center of town offered me a job - *after a bit of pestering from myself*. In the 3 and a half years I was a pizza chef I studied culinary arts and helped them build their business by managing sites and opening new sites, etc.
Needing a new challenge I decided to move to Japan and break away from pizza. There I met my Sous Chef who had worked in Michelin starred restaurants. He inspired me to push myself even further and after a year-ish in Japan I decided to go to London and really test my mettle.
I got a job at a 1 star restaurant which was the hardest work, but also the most gratifying. In 2020, as everyone is aware by now, the pandemic hit. The hospitality industry was devastated by the effects of the pandemic.
With a bunch of free time on my hands, I decided to learn how to do some basic coding through Free Code Camp, Codecademy, and Code wars. Restrictions were easing and I was called back into the kitchen where, I found that I no longer had the passion I once had for cooking. This prompted me to get serious about software development. I joined Makers Academy in July 2021, once finished I applied to a bunch of different jobs, one of which being this DevOps apprenticeship with Credera.

### About Credera

Credera is a consulting firm focused on strategy, innovation, data, and technology. As a part of Omnicom Precision Marketing Group, Credera's approximately 3000 consultants across the globe partner with clients ranging from FTSE 100 companies and public sector giants to emerging industry leaders from strategy to execution to create tangible business results. Credera's deep business acumen and technical expertise, combined with a deep dedication to building trusted relationships, unlock extraordinary business performance for their clients. Its mission is to make an extraordinary impact on its clients, people, and communities.

## Knowledge, Skills and Behaviours

| KSB Number | KSB Description |
|:----------:|-----------------|
| **Knowledge** | |
| K1 | Continuous Integration - the benefits of frequent merging of code, the creation of build artefacts and ensuring all tests pass, with automation throughout - including common tooling. |
| K2 | The principles of distributed Source Control, including how to exploit the features of the tool, such as branching. |
| <a id="K3">K3</a> | How to use data ethically and the implications for wider society, with respect to the use of data, automation and artificial intelligence within the context of relevant data protection policy and legislation. |
| K4 | The business value of DevOps in terms of Time, Cost, Quality, with an emphasis on building in internal Quality throughout the lifetime of the product. |
| K5 | A range of modern security tools and techniques - e.g. threat modelling, vulnerability scanning and dependency checking, with a general awareness of penetration testing - in order to deal with threats and attack vectors within code and across the cyber domain. |
| K6 | A range of problem solving techniques appropriate to the task at hand, such as affinity mapping, impact maps, plan-do-check-act/Deming. |
| K7 | General purpose programming and infrastructure-as-code. |
| K8 | Immutable infrastructure and how it enables continuous refreshing of software, namely the updating of the operating system, container and security patching. |
| K9 | Different organisational cultures, the development frameworks utilised and how they can both complement each other and introduce constraints on delivery. |
| K10 | How the user experience sits at the heart of modern development practices in terms of strategies to understand diverse user needs, accessibility and how to drive adoption. |
| K11 | Monitoring and alerting technologies and an awareness of the insights that can be derived from the infrastructure and applications - collecting logs and metrics, configuring alerting thresholds, firing alerts and visualising data. |
| K12 | The persistence/data layer, including which database/storage technologies are appropriate to each platform type and application when considering non-functional and functional needs; e.g. monolith, microservice, read heavy, write heavy, recovery plans. |
| K13 | Automation techniques, such as scripting and use of APIs. |
| K14 | Test Driven Development and the Test Pyramid. How the practice is underpinned by unit testing, the importance of automation, appropriate use of test doubles and mocking strategies, reducing a reliance on end-to-end testing. |
| K15 | The principles and application of Continuous Integration, Continuous Delivery and Continuous Deployment, including the differences between them. |
| K16 | How best to secure data; e.g. encryption in transit, encryption at rest and access control lists (ACL). |
| K17 | What an API is, how to find them and interpret the accompanying documentation. |
| K18 | Roles within a multidisciplinary team and the interfaces with other areas of an organisation. |
| K19 | Different methods of communication and choosing the appropriate one - e.g. face-to-face (synchronous, high bandwidth), instant messaging, email (asynchronous, low bandwidth), visualisations vs. words. |
| K20 | Pair/mob programming techniques and when to use each technique. |
| K21 | Architecture principles, common patterns and common strategies for translating user needs into both cloud infrastructure and application code. |
| K22 | How their occupation fits into the wider digital landscape and any current or future regulatory requirements. |
| K23 | The importance of continual improvement within a blameless culture. |
| K24 | The difference between Software-as-a-Service (SaaS) v bespoke v enterprise tooling and how to make an informed choice that suits each use case. |
| K25 | Maintain an awareness of cloud certification requirements. |
| **Skills** | |
| S1 | Communicate credibly with technical and non-technical people at all levels, using a range of methods; e.g. ‘Show and Tell’ and ‘Demonstrations’. |
| S2 | Work within different organisational cultures with both internal and external parties. |
| S3 | Translate user needs into deliverable tasks, writing clear, concise and unambiguous user stories that the whole team can understand. |
| S4 | Initiate and facilitate knowledge sharing and technical collaboration. |
| S5 | Deploy immutable infrastructure. |
| S6 | Install, manage and troubleshoot monitoring tools. |
| S7 | Navigate and troubleshoot stateful distributed systems, in order to locate issues across the end-to-end service. |
| S8 | Work in agile, multi-disciplinary delivery teams, taking a flexible, collaborative and pragmatic approach to delivering tasks. |
| S9 | Application of a range of cloud security tools and techniques - e.g. threat modelling, vulnerability scanning, dependency checking, reducing attack surface area - incorporating these tools and techniques into the automated pipeline wherever possible. |
| S10 | Assess identified and potential security threats and take appropriate action based on likelihood v impact. |
| S11 | Employ a systematic approach to solving problems, using logic and hypotheses / experimentation to identify the source of issues. |
| S12 | Automate tasks where it introduces improvements to the efficiency of business processes and reduces waste, considering the effort and cost of automation. |
| S13 | Engage in productive pair/mob programming. |
| S14 | Write tests and follow Test Driven Development discipline in various different contexts. |
| S15 | Release automation and orchestration as part of a Continuous Integration workflow and Continuous Delivery pipeline, automating the delivery of code from source control to the end users. |
| S16 | Invest in continuous learning, both your own development and others, ensuring learning activities dovetail with changing job requirements. Keep up with cutting edge. |
| S17 | Code in a general purpose programming language. |
| S18 | Specify cloud infrastructure in an infrastructure-as-code domain-specific language. |
| S19 | Interpret logs and metrics data within the appropriate context to identify issues and make informed decisions. |
| S20 | Writing code in such a way that makes merging easier and facilitates branching by abstraction - i.e. feature toggling. |
| S21 | Application of lightweight modelling techniques, such as whiteboarding, in order to gain consensus as a team on evolving architecture. |
| S22 | Incremental refactoring by applying small behaviour-preserving code changes to evolve the architecture. |
| **Behaviours** | |
| B1 | Exhibits enthusiasm, openness and an aptitude for working as part of a collaborative community; e.g. sharing best practice, pairing with team members, learning from others and engaging in peer review practices. |
| B2 | Invests time and effort in their own development, recognising that technology evolves at a rapid rate. |
| B3 | Displays a commitment to the mantra 'You build it, you run it', taking ownership of deployed code and being accountable for its continual improvement, learning from experience and taking collective responsibility when things fail. |
| B4 | Is inclusive, professional and maintains a blameless culture. |

## Releases

| KSB Number | KSB Description | Which ticket(s) | Overview of how I met it | Ticket Date | Document Link |
|:----------:|-----------------|:---------------:|--------------------------|-------------|---------------|
| [K3](#K3) | How to use data ethically and the implications for wider society, with respect to the use of data, automation and artificial intelligence within the context of relevant data protection policy and legislation. | | | | |
| K6 | A range of problem solving techniques appropriate to the task at hand, such as affinity mapping, impact maps, plan-do-check-act/Deming. | | | | |
| K9 | Different organisational cultures, the development frameworks utilised and how they can both complement each other and introduce constraints on delivery. | | | | |
| K18 | Roles within a multidisciplinary team and the interfaces with other areas of an organisation. | | | | |
| K19 | Different methods of communication and choosing the appropriate one - e.g. face-to-face (synchronous, high bandwidth), instant messaging, email (asynchronous, low bandwidth), visualisations vs. words. | | | | |
| K20 | Pair/mob programming techniques and when to use each technique. | | | | |
| K22 | How their occupation fits into the wider digital landscape and any current or future regulatory requirements. | | | | |
| K23 | The importance of continual improvement within a blameless culture. | | | | |
| K24 | The difference between Software-as-a-Service (SaaS) v bespoke v enterprise tooling and how to make an informed choice that suits each use case. | | | | |
| K25 | Maintain an awareness of cloud certification requirements. | | | | |


## Table of Tickets

| Ticket number | Ticket |
|:-:|--------------------|
| 1 | ![Auto tagging ticket](./images/auto_tagging_ticket.png) |

## Ticket 1

### Project Background

When joining Credera, depending on client engagements at the time, generally you'll be assigned to the bench to help create/improve internal products, this is only while you're not on a client. While on the bench, I didn't have the opportunity to do much as part of a team.
Every Monday and Wednesday there is a bench stand up where we discuss progress made or blockers on tickets we've been assigned to. You based on your interests, if nothing takes your fancy you will get assigned a ticket based on your experience.

### Ticket Background

This is part of an epic and was created as a ticket. I chose the ticket as it looked interesting and I hadn't done anything like this before. I would assume there were meetings before I was assigned to the ticket, as it was created before I joined. Because I had no idea what I was doing, I broke the ticket down into 2 steps in the beginning, manually test to see if the requirements are even possible, and then automate the process.

### Learning and Research

I had done a weeks worth of Terraform in the training before going onto placement, so I had to learn more about Terraform. I had to deepen my knowledge on AWS.

### Completing the Ticket

Majority of this task was solo work, a couple of times I got stuck on something to do with Terraform or the way the AWS environment I was deploying to was configured.

In the beginning I had no clue if this was possible, so I spent a lot of time googling. I found a video of someone who had implemented something similar through the UI. Seeing this I created a diagram of how I thought it was working - *this is the end result, in the beginning it only referenced the creation of S3 buckets*

![Autotagger Diagram](./images/Autotagger-Diagram.png)

With this in mind, I converted the diagram into Terraform, adding the missing parts that are auto-generated/easily overlooked as it could be a simple click of a button through the UI. My first step was to create a Lambda that would trigger on a specific event, *eg. a user creates an S3 bucket*, and have the Lambda log something simple.

#### Trigger Evidence

![trigger evidence](./images/creation-event.png)

Once I had evidence that the creation events were triggering the Lambda, I could then implement the logic that would provide the created resources with new tags.
Using the AWS SDK for python, *Boto3*, I could easily hit the AWS API and create an S3 client, scrape the logs for the bucket name, then provide the S3 client the bucket name, and then with an S3 client built-in function provide the bucket the required tags.

#### Lambda Handler

![lambda handler](./images/lambda-handler.png)

#### Tagging function

![bucket tagging](./images/bucket-tagging.png)

Once this has been deployed, and you create an S3 bucket, when you check your newly created bucket you'll see that there are now tags attached to it:
![tagged bucket](./images/tagged-bucket.png)

Once I could tag a bucket, targeting other resources was very easy, it was just a matter of changing the Boto3 resource I needed.

I chose to use Python in this project for three reasons:

* I hadn't used it before, I wanted to challenge myself
* It had minimal setup versus Javascript when using the AWS SDK
* It's quick and easy to pick up
* It looks cleaner

I used Terraform as the IAC as that's what I had the most familiarity with thanks to Makers and their crash course on DevOps.

### Problems and Solutions

One of the problems I faced when trying to tag S3 buckets, was that Boto3 didn't have a way to cleanly add tags to the bucket, so it would overwrite any tags it already had. I got around this by retrieving the tags that were attached to the bucket on creation and adding them to the list of tags that I wanted to provide.

Another issue I faced when expanding this project to incorporate more than just S3 buckets was, not all AWS resource take tags in the same way, which made this frustrating when I wanted to follow best practices and not repeat code, eg. S3 buckets, the accepted tags are formatted like so:

```python
'TagSet': [
  {'Key': 'CreatedBy', 'Value': user},
  {'Key': 'CreatedOn', 'Value': current_date}
]
```

but if I tried to do the same with an EKS cluster, all it would accept is the following:

```python
{
  'CreatedBy': user,
  'CreatedOn': current_date
}
```

### Conclusion

I was able to implement auto tagging for 5 different resources, S3 buckets, EC2 instances, ECK clusters, ECS clusters, and Glue registries. I made it easy to implement the logic for other resources by documenting thoroughly the approach one should take.
I learned some basic use of Python, deepened my knowledge on Terraform and AWS
This has helped by allowing Credera to pinpoint when and who created a resource, and track how much these resources are costing the company.
